ChunkSize选择TIPS
• 数据的预填充（数据字段在插入时就赋予初始值）是一件十分重要的事情，
• 虽然浪费的一部分空间，但是数据块分裂的次数变少了，数据块只在最初填充时分裂，
• 获得了平滑的RU（查改）性能。

ChunkSize选择
• 选择小的ChunkSize
– 优点
» 数据均衡时迁移速度更快
» 数据分布更均匀
– 缺点
» 数据均衡会更频繁
» 块之间的数据分裂更频繁（当一个块的数据超过块大小的50%时，块就开始分裂）
» 在路由节点会消耗更多的资源用於定位

较大的ChunkSize
– 优点
» 数据块更少进行分裂操作
» 由层开销更小（config定位块更迅捷）
» 避免虚假的迁移（一块数据，在两个节点间来回移动）
– 缺点
» 数据块移动将集中消耗IO资源（这点很可怕，抖动和数据值不准都有可能会产生）
» 数据分布不太均匀


MongoDB的update默认是更新一条，同样是上面的情况，就有可能出现，两次相同的更新，无法保证只在所有
分片上只更新一条记录，解决方案：请在update条件上带上sharding key，这样路由节点就能准确的路由这条更
新去指定的片，以保证唯一。



MongoDB的分片实现
– MongoDB的分片是指定一个分片key来进行，数据按范围分成不同的chunk，每个chunk的大小有限制
– 有多个分片节点保存这些chunk，每个节点保存一部分的chunk
– 每一个分片节点都是一个Replica Set，这样保证数据的安全性、可用性、可靠性
– 当一个chunk超过其限制的最大体积时，会分裂成两个小的chunk
– 当chunk在分片节点中分布不均衡时，会引发chunk迁移操作
• TIPS
– 每个chunk的大小有限制
» 如果不做预分配而不断填入数据，那么chunk肯定是会分裂的，导致的结果->更多的IO消耗
– 当chunk在分片节点中分布不均衡时，会引发chunk迁移操作
» 节点之间会有数据均衡，消耗IO资源，并会造成部分特定的查询返回值不准确


随机的sharding key
– 数据分布均匀，insert的写IO均匀分布在多个片上（优势）
– 大量的随机IO，磁盘不堪重荷


混合型的KEY，我们的设计优先考虑
– {大范围的递增键：1，随机分布的键：1}
– 例如：{月份，用户名}
– 第一个key大方向单调增
– 第二个key随机分布
• 原由
– 大方向单调增，保证数据不断写新的数据文件，以保证文件写的性能（顺序写性能高）
– 尽量不要让写分布在一个节点的多个文件里去做（选择适合的ChunkSize）（由MongoDB的内存管理方式决定，
MongoDB写的数据，一定是内存中映射了的）
– 小方向随机分布，保证数据可基本均匀分布在两个分片上，分摊读写压力到各个分片中
• TIPS
– 不是所有场景都适合的
» Key的不可更新性以及Map-Reduce的消耗



MongoDB数据模型选择
• CAP定理（Consistency ，Availability 和Partition Tolerance )
– Consistency(一致性)：数据一致更新，所有数据变动都是同步的
– Availability(可用性)：好的响应性能
– Partition Tolerance(分区容错性)：数据可靠性
– 分布式系统三选二
• 官方CP模型
• CP
– Replica Set,设置写入节点数w=Replica Set数据节点数，查询开启SlaveOk
• AP
– Replica Set,默认设置w=1，查询开启slaveOk
• CA
– Replica Set,默认设置w=1，查询不开启slaveOk
• 根据业务的实际需求，选择合适的数据模型！



MongoDB库设计原则及实践
• 库设计
– 对业务增长情况要要求
» 目前是什么量级
» 半年~一年是什么量级
– 库分片
» Sharding分片数量
– 容量规划的关键原则
» Memory > Index + Hot Data
» 索引+热数据要全部加载到内存(MMAP）
• MongoDB的高性能



MongoDB库设计原则与实践
• 如何设计频繁更新删除记录的collection
– MongoDB的数据库是按文件来存储的
» 例如：db1下的所有collection都放在一组文件内db1.0,db1.1,db1.2,db1.3…
– 将频繁更新删除的表放在一个独立的数据库下，将会减少碎片，并提高性能
• 单库单表绝对不是最好的选择
– 原因有三：
» 表越多，映射文件越多，从MongoDB的内存管理方式来看，浪费越多
» 同理，表越多，回写和读取的时候，无法合并IO资源，大量的随机IO对传统硬盘是致命的
» 单表数据量大，索引占用高，更新和读取速度慢
• Local库
– Local库主要存放oplog，oplog同样是要消耗内存的
– 选择一个合适的oplog值，很重要
– 高插入高更新，并带有延时从库的副本集需要一个较大的oplog值（比如20G）
– 如果没有延时从库，则可以适当放小oplog值

### MongoDB导致MongoDB集群性能低下原因是什么
数据量增大
– 热点数据超过物理内存大小
– 数据频繁的SWAP
– 必然性能低下
• 内存容量规划
– Memory > Hot Data + Index
• 启发
– 加大内存容量

数据空洞
– 大量删除数据
– 造成大量的数据碎片和空洞
– 内存中含有空洞数据
– 利用率低
• 数据收缩
– Online compact
– Offline 收缩
– 数据库无空洞，数据无碎片，数据紧凑，性能高.


### 
字段名选取
• Free Schema means Repeat the Schema in every docs
– 所有的字段名在每行记录中都要完全重复存储
– 存储空间浪费较大
• 字段名尽可能的短 （Use Short Key Names）
– 减少字段名本身的空间存储大小



字段名选取
• 减少字段名较少存储空间
– {name:”musicml”, age:”28”, sex:”male“}
– {n:”musicml”, a:”28”, s:”male”}
– 新的问题
» 字段名的可读性问题
» name->名字，age->年龄，sex->性别
» n->?, a->?, s->?
– 如解决可读性的问题
» 应用层做字段名的映射



_id如何生成
– _id生成
• 在客户端生成
– 根据业务情况选择合适的_id
» 比如IM用户信息表
• 用户uid、用户登录名、用户昵称、用户签名等
• 使用uid做为_id
• uint64_t
• _id字段存储空间由12字节减少为8字节
• 在客户端生成
» 减少了MongoDB服务器计算压力
» 根据业务情况，使用合适类型的_id，灵活控制，同时减少数据存储空间
– 建议所有的Collection中的_id在业务层统一生成


### Collection索引如何设计


Collection索引如何设计
– 索引有什么用
• 内存的读取速度比硬盘快100倍
• 要求索引在内存，提高查询速度
• 增加内存
– 32G->64G->96G->128G……
• 使用SSD
– 索引类型
• 唯一性索引
– db.userinfo.ensureIndex({“uid”: 1}，{“unique”: true});
– 保证了索引项的唯一性
• 联合索引
– 多个字段联合构成索引 db.onelinemsg.ensureIndex({“uid”: 1, msgid : 1 }，{“unique”: true});
– 支持前缀查询


读取场景&相应索引设计
• 查询返回某些字段，而这些字段都可以放在索引中
– 索引覆盖查询


联合查询
– 支持前缀索引查询（加快多个查询）


读取场景&相应索引设计
• 查询返回95%的集合文档数据
– 假设索引大小50G，文档大小200G
– 假设继续使用索引，需要加载到内存约250G
» 50G索引+200G文档
– 假设不使用索引，全表扫描
» 200G的文档
» 更快
• 不要到处使用索引，索引使用要适中
– 返回小数据量的文档，建议使用索引
– 返回>=50%文档数据时，不建议在使用索引



• 索引副作用
– 增加、删除、更新记录
– 索引相应增加、删除、更新
– 增加MongoDB服务端开销


后台索引
– 命令
» db.onlinemsg.ensureIndex({uid : 1, msgid : 1, srcuid : 1}， {background : true});
– 不允许暂定数据库访问
– 可以在后台构建索引
– 构建后台索引仍然会占用写锁，但是会释放给业务读写操作
– MongoDB对外读写性能会下降



Collection空间地理索引是否靠谱
– 空间地理索引
• 移动互联网的兴起
• 根据经度、维度查询需求
• 查询给定坐标经纬度附近的餐馆
– MongoDB提供了地理空间索引
• 创建空间地理索引
– db.map.ensureIndex({gps : 2d});
• 查询
– db.map.find({gps : { $near : [100, -100]}});
– Collection空间地理索引靠谱吗
• 地理空间索引查询和重构消耗过多CPU资源问题
– 机器卡死（不建议使用、通过搜索等业务搞定）


### Collection 单表数据量大如何Sharding

Collection Sharding
• 手动Sharding
– 如何手动Sharding
• 单表千万量级
• 单ID查询key水平拆分表
– 用户信息表
» {uid, loginname, sign, ……}
» 按照uid水平拆分
• uid%64
» 按照uid的查询
– 可控、可靠
– 避免了Auto-Sharding带来的不稳定因素